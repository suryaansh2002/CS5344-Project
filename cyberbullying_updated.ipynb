{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Hate Speech Classification and Cyberbullying Detection\n",
    "\n",
    "This notebook implements a multimodal model combining image and text features for hate speech detection and cyberbullying classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Annotations and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:24.009688Z",
     "iopub.status.busy": "2024-11-21T08:05:24.008899Z",
     "iopub.status.idle": "2024-11-21T08:05:36.931305Z",
     "shell.execute_reply": "2024-11-21T08:05:36.93038Z",
     "shell.execute_reply.started": "2024-11-21T08:05:24.009637Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import torch\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:39.391255Z",
     "iopub.status.busy": "2024-11-21T08:05:39.390689Z",
     "iopub.status.idle": "2024-11-21T08:05:40.694199Z",
     "shell.execute_reply": "2024-11-21T08:05:40.693513Z",
     "shell.execute_reply.started": "2024-11-21T08:05:39.391221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the annotations\n",
    "with open('./multimodal-hate-speech/MMHS150K_GT.json', 'r') as f:\n",
    "    annotations = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:40.695854Z",
     "iopub.status.busy": "2024-11-21T08:05:40.695587Z",
     "iopub.status.idle": "2024-11-21T08:05:41.206643Z",
     "shell.execute_reply": "2024-11-21T08:05:41.205392Z",
     "shell.execute_reply.started": "2024-11-21T08:05:40.695827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the JSON dict to a DataFrame\n",
    "data = []\n",
    "for tweet_id, info in annotations.items():\n",
    "    data.append({\n",
    "        'tweet_id': tweet_id,\n",
    "        'tweet_text': info['tweet_text'],\n",
    "        'labels': info['labels'],\n",
    "        'labels_str': info['labels_str']\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1114679353714016256</td>\n",
       "      <td>@FriskDontMiss Nigga https://t.co/cAsaLWEpue</td>\n",
       "      <td>[4, 1, 3]</td>\n",
       "      <td>[Religion, Racist, Homophobe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1063020048816660480</td>\n",
       "      <td>My horses are retarded https://t.co/HYhqc6d5WN</td>\n",
       "      <td>[5, 5, 5]</td>\n",
       "      <td>[OtherHate, OtherHate, OtherHate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1108927368075374593</td>\n",
       "      <td>“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[NotHate, NotHate, NotHate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1114558534635618305</td>\n",
       "      <td>RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[Racist, NotHate, NotHate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035252480215592966</td>\n",
       "      <td>“EVERYbody calling you Nigger now!” https://t....</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>[Racist, NotHate, Racist]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0  1114679353714016256       @FriskDontMiss Nigga https://t.co/cAsaLWEpue   \n",
       "1  1063020048816660480     My horses are retarded https://t.co/HYhqc6d5WN   \n",
       "2  1108927368075374593  “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...   \n",
       "3  1114558534635618305  RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...   \n",
       "4  1035252480215592966  “EVERYbody calling you Nigger now!” https://t....   \n",
       "\n",
       "      labels                         labels_str  \n",
       "0  [4, 1, 3]      [Religion, Racist, Homophobe]  \n",
       "1  [5, 5, 5]  [OtherHate, OtherHate, OtherHate]  \n",
       "2  [0, 0, 0]        [NotHate, NotHate, NotHate]  \n",
       "3  [1, 0, 0]         [Racist, NotHate, NotHate]  \n",
       "4  [1, 0, 1]          [Racist, NotHate, Racist]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Image Path and Create Majority Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:41.208023Z",
     "iopub.status.busy": "2024-11-21T08:05:41.207721Z",
     "iopub.status.idle": "2024-11-21T08:05:41.211936Z",
     "shell.execute_reply": "2024-11-21T08:05:41.211031Z",
     "shell.execute_reply.started": "2024-11-21T08:05:41.207994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Path to the image folder\n",
    "image_folder = './multimodal-hate-speech/img_resized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:41.213784Z",
     "iopub.status.busy": "2024-11-21T08:05:41.213523Z",
     "iopub.status.idle": "2024-11-21T08:05:41.390719Z",
     "shell.execute_reply": "2024-11-21T08:05:41.38999Z",
     "shell.execute_reply.started": "2024-11-21T08:05:41.213758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Add image path column\n",
    "df['image_path'] = df['tweet_id'].apply(lambda x: os.path.join(image_folder, f\"{x}.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:41.392012Z",
     "iopub.status.busy": "2024-11-21T08:05:41.391731Z",
     "iopub.status.idle": "2024-11-21T08:05:41.396483Z",
     "shell.execute_reply": "2024-11-21T08:05:41.395507Z",
     "shell.execute_reply.started": "2024-11-21T08:05:41.391985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define majority vote function for labels\n",
    "from collections import Counter\n",
    "\n",
    "def majority_vote(labels):\n",
    "    label_count = Counter(labels)\n",
    "    return label_count.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:41.397617Z",
     "iopub.status.busy": "2024-11-21T08:05:41.397384Z",
     "iopub.status.idle": "2024-11-21T08:05:41.813827Z",
     "shell.execute_reply": "2024-11-21T08:05:41.8129Z",
     "shell.execute_reply.started": "2024-11-21T08:05:41.397594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Apply majority vote to create a single label column\n",
    "df['majority_label'] = df['labels'].apply(majority_vote)\n",
    "\n",
    "label_mapping = {\n",
    "    0: \"NotHate\",\n",
    "    1: \"Racist\",\n",
    "    2: \"Sexist\",\n",
    "    3: \"Homophobe\",\n",
    "    4: \"Religion\",\n",
    "    5: \"OtherHate\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_str</th>\n",
       "      <th>image_path</th>\n",
       "      <th>majority_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1114679353714016256</td>\n",
       "      <td>@FriskDontMiss Nigga https://t.co/cAsaLWEpue</td>\n",
       "      <td>[4, 1, 3]</td>\n",
       "      <td>[Religion, Racist, Homophobe]</td>\n",
       "      <td>./multimodal-hate-speech/img_resized/111467935...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1063020048816660480</td>\n",
       "      <td>My horses are retarded https://t.co/HYhqc6d5WN</td>\n",
       "      <td>[5, 5, 5]</td>\n",
       "      <td>[OtherHate, OtherHate, OtherHate]</td>\n",
       "      <td>./multimodal-hate-speech/img_resized/106302004...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1108927368075374593</td>\n",
       "      <td>“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[NotHate, NotHate, NotHate]</td>\n",
       "      <td>./multimodal-hate-speech/img_resized/110892736...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1114558534635618305</td>\n",
       "      <td>RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[Racist, NotHate, NotHate]</td>\n",
       "      <td>./multimodal-hate-speech/img_resized/111455853...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035252480215592966</td>\n",
       "      <td>“EVERYbody calling you Nigger now!” https://t....</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>[Racist, NotHate, Racist]</td>\n",
       "      <td>./multimodal-hate-speech/img_resized/103525248...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0  1114679353714016256       @FriskDontMiss Nigga https://t.co/cAsaLWEpue   \n",
       "1  1063020048816660480     My horses are retarded https://t.co/HYhqc6d5WN   \n",
       "2  1108927368075374593  “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...   \n",
       "3  1114558534635618305  RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...   \n",
       "4  1035252480215592966  “EVERYbody calling you Nigger now!” https://t....   \n",
       "\n",
       "      labels                         labels_str  \\\n",
       "0  [4, 1, 3]      [Religion, Racist, Homophobe]   \n",
       "1  [5, 5, 5]  [OtherHate, OtherHate, OtherHate]   \n",
       "2  [0, 0, 0]        [NotHate, NotHate, NotHate]   \n",
       "3  [1, 0, 0]         [Racist, NotHate, NotHate]   \n",
       "4  [1, 0, 1]          [Racist, NotHate, Racist]   \n",
       "\n",
       "                                          image_path  majority_label  \n",
       "0  ./multimodal-hate-speech/img_resized/111467935...               4  \n",
       "1  ./multimodal-hate-speech/img_resized/106302004...               5  \n",
       "2  ./multimodal-hate-speech/img_resized/110892736...               0  \n",
       "3  ./multimodal-hate-speech/img_resized/111455853...               0  \n",
       "4  ./multimodal-hate-speech/img_resized/103525248...               1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:41.815664Z",
     "iopub.status.busy": "2024-11-21T08:05:41.814991Z",
     "iopub.status.idle": "2024-11-21T08:05:41.827376Z",
     "shell.execute_reply": "2024-11-21T08:05:41.826644Z",
     "shell.execute_reply.started": "2024-11-21T08:05:41.815624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a new column 'majority_label_str' with the string representation of the majority label\n",
    "df['majority_label_str'] = df['majority_label'].map(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:41.828985Z",
     "iopub.status.busy": "2024-11-21T08:05:41.828325Z",
     "iopub.status.idle": "2024-11-21T08:05:41.845571Z",
     "shell.execute_reply": "2024-11-21T08:05:41.844798Z",
     "shell.execute_reply.started": "2024-11-21T08:05:41.828958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_str</th>\n",
       "      <th>image_path</th>\n",
       "      <th>majority_label</th>\n",
       "      <th>majority_label_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1114679353714016256</td>\n",
       "      <td>@FriskDontMiss Nigga https://t.co/cAsaLWEpue</td>\n",
       "      <td>[4, 1, 3]</td>\n",
       "      <td>[Religion, Racist, Homophobe]</td>\n",
       "      <td>./multimodal-hate-speech/img_resized/111467935...</td>\n",
       "      <td>4</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1063020048816660480</td>\n",
       "      <td>My horses are retarded https://t.co/HYhqc6d5WN</td>\n",
       "      <td>[5, 5, 5]</td>\n",
       "      <td>[OtherHate, OtherHate, OtherHate]</td>\n",
       "      <td>./multimodal-hate-speech/img_resized/106302004...</td>\n",
       "      <td>5</td>\n",
       "      <td>OtherHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1108927368075374593</td>\n",
       "      <td>“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[NotHate, NotHate, NotHate]</td>\n",
       "      <td>./multimodal-hate-speech/img_resized/110892736...</td>\n",
       "      <td>0</td>\n",
       "      <td>NotHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1114558534635618305</td>\n",
       "      <td>RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[Racist, NotHate, NotHate]</td>\n",
       "      <td>./multimodal-hate-speech/img_resized/111455853...</td>\n",
       "      <td>0</td>\n",
       "      <td>NotHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035252480215592966</td>\n",
       "      <td>“EVERYbody calling you Nigger now!” https://t....</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>[Racist, NotHate, Racist]</td>\n",
       "      <td>./multimodal-hate-speech/img_resized/103525248...</td>\n",
       "      <td>1</td>\n",
       "      <td>Racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0  1114679353714016256       @FriskDontMiss Nigga https://t.co/cAsaLWEpue   \n",
       "1  1063020048816660480     My horses are retarded https://t.co/HYhqc6d5WN   \n",
       "2  1108927368075374593  “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...   \n",
       "3  1114558534635618305  RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...   \n",
       "4  1035252480215592966  “EVERYbody calling you Nigger now!” https://t....   \n",
       "\n",
       "      labels                         labels_str  \\\n",
       "0  [4, 1, 3]      [Religion, Racist, Homophobe]   \n",
       "1  [5, 5, 5]  [OtherHate, OtherHate, OtherHate]   \n",
       "2  [0, 0, 0]        [NotHate, NotHate, NotHate]   \n",
       "3  [1, 0, 0]         [Racist, NotHate, NotHate]   \n",
       "4  [1, 0, 1]          [Racist, NotHate, Racist]   \n",
       "\n",
       "                                          image_path  majority_label  \\\n",
       "0  ./multimodal-hate-speech/img_resized/111467935...               4   \n",
       "1  ./multimodal-hate-speech/img_resized/106302004...               5   \n",
       "2  ./multimodal-hate-speech/img_resized/110892736...               0   \n",
       "3  ./multimodal-hate-speech/img_resized/111455853...               0   \n",
       "4  ./multimodal-hate-speech/img_resized/103525248...               1   \n",
       "\n",
       "  majority_label_str  \n",
       "0           Religion  \n",
       "1          OtherHate  \n",
       "2            NotHate  \n",
       "3            NotHate  \n",
       "4             Racist  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_bert(text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=128, return_tensors=\"tf\")\n",
    "    # Get BERT embeddings\n",
    "    outputs = bert_model(inputs)\n",
    "    # Use the [CLS] token embedding (first token)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:41.847558Z",
     "iopub.status.busy": "2024-11-21T08:05:41.847275Z",
     "iopub.status.idle": "2024-11-21T08:05:41.852162Z",
     "shell.execute_reply": "2024-11-21T08:05:41.851391Z",
     "shell.execute_reply.started": "2024-11-21T08:05:41.847532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preprocess text data\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_bert(texts, batch_size=32):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    \n",
    "    all_embeddings = []\n",
    "    total_batches = len(texts) // batch_size + (1 if len(texts) % batch_size != 0 else 0)\n",
    "    \n",
    "    print(f\"Processing {len(texts)} texts in {total_batches} batches...\")\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize the batch\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=64,\n",
    "            return_tensors=\"tf\"\n",
    "        )\n",
    "        \n",
    "        # Get BERT embeddings for the batch\n",
    "        outputs = bert_model(inputs)\n",
    "        \n",
    "        # Use [CLS] token embedding (first token)\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "        \n",
    "        # Print progress\n",
    "        if (i // batch_size) % 10 == 0:\n",
    "            print(f\"Processed {i} texts...\")\n",
    "    \n",
    "    # Concatenate all batch embeddings\n",
    "    final_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    print(f\"Completed processing {len(final_embeddings)} texts\")\n",
    "    return final_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df.sample(n=50000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:41.853237Z",
     "iopub.status.busy": "2024-11-21T08:05:41.853022Z",
     "iopub.status.idle": "2024-11-21T08:05:43.069737Z",
     "shell.execute_reply": "2024-11-21T08:05:43.06903Z",
     "shell.execute_reply.started": "2024-11-21T08:05:41.853214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Apply text preprocessing\n",
    "sampled_df['cleaned_text'] = sampled_df['tweet_text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Splitting and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50000 texts in 1563 batches...\n",
      "Processed 0 texts...\n",
      "Processed 320 texts...\n",
      "Processed 640 texts...\n",
      "Processed 960 texts...\n",
      "Processed 1280 texts...\n",
      "Processed 1600 texts...\n",
      "Processed 1920 texts...\n",
      "Processed 2240 texts...\n",
      "Processed 2560 texts...\n",
      "Processed 2880 texts...\n",
      "Processed 3200 texts...\n",
      "Processed 3520 texts...\n",
      "Processed 3840 texts...\n",
      "Processed 4160 texts...\n",
      "Processed 4480 texts...\n",
      "Processed 4800 texts...\n",
      "Processed 5120 texts...\n",
      "Processed 5440 texts...\n",
      "Processed 5760 texts...\n",
      "Processed 6080 texts...\n",
      "Processed 6400 texts...\n",
      "Processed 6720 texts...\n",
      "Processed 7040 texts...\n",
      "Processed 7360 texts...\n",
      "Processed 7680 texts...\n",
      "Processed 8000 texts...\n",
      "Processed 8320 texts...\n",
      "Processed 8640 texts...\n",
      "Processed 8960 texts...\n",
      "Processed 9280 texts...\n",
      "Processed 9600 texts...\n",
      "Processed 9920 texts...\n",
      "Processed 10240 texts...\n",
      "Processed 10560 texts...\n",
      "Processed 10880 texts...\n",
      "Processed 11200 texts...\n",
      "Processed 11520 texts...\n",
      "Processed 11840 texts...\n",
      "Processed 12160 texts...\n",
      "Processed 12480 texts...\n",
      "Processed 12800 texts...\n",
      "Processed 13120 texts...\n",
      "Processed 13440 texts...\n",
      "Processed 13760 texts...\n",
      "Processed 14080 texts...\n",
      "Processed 14400 texts...\n",
      "Processed 14720 texts...\n",
      "Processed 15040 texts...\n",
      "Processed 15360 texts...\n",
      "Processed 15680 texts...\n",
      "Processed 16000 texts...\n",
      "Processed 16320 texts...\n",
      "Processed 16640 texts...\n",
      "Processed 16960 texts...\n",
      "Processed 17280 texts...\n",
      "Processed 17600 texts...\n",
      "Processed 17920 texts...\n",
      "Processed 18240 texts...\n",
      "Processed 18560 texts...\n",
      "Processed 18880 texts...\n",
      "Processed 19200 texts...\n",
      "Processed 19520 texts...\n",
      "Processed 19840 texts...\n",
      "Processed 20160 texts...\n",
      "Processed 20480 texts...\n",
      "Processed 20800 texts...\n",
      "Processed 21120 texts...\n",
      "Processed 21440 texts...\n",
      "Processed 21760 texts...\n",
      "Processed 22080 texts...\n",
      "Processed 22400 texts...\n",
      "Processed 22720 texts...\n",
      "Processed 23040 texts...\n",
      "Processed 23360 texts...\n",
      "Processed 23680 texts...\n",
      "Processed 24000 texts...\n",
      "Processed 24320 texts...\n",
      "Processed 24640 texts...\n",
      "Processed 24960 texts...\n",
      "Processed 25280 texts...\n",
      "Processed 25600 texts...\n",
      "Processed 25920 texts...\n",
      "Processed 26240 texts...\n",
      "Processed 26560 texts...\n",
      "Processed 26880 texts...\n",
      "Processed 27200 texts...\n",
      "Processed 27520 texts...\n",
      "Processed 27840 texts...\n",
      "Processed 28160 texts...\n",
      "Processed 28480 texts...\n",
      "Processed 28800 texts...\n",
      "Processed 29120 texts...\n",
      "Processed 29440 texts...\n",
      "Processed 29760 texts...\n",
      "Processed 30080 texts...\n",
      "Processed 30400 texts...\n",
      "Processed 30720 texts...\n",
      "Processed 31040 texts...\n",
      "Processed 31360 texts...\n",
      "Processed 31680 texts...\n",
      "Processed 32000 texts...\n",
      "Processed 32320 texts...\n",
      "Processed 32640 texts...\n",
      "Processed 32960 texts...\n",
      "Processed 33280 texts...\n",
      "Processed 33600 texts...\n",
      "Processed 33920 texts...\n",
      "Processed 34240 texts...\n",
      "Processed 34560 texts...\n",
      "Processed 34880 texts...\n",
      "Processed 35200 texts...\n",
      "Processed 35520 texts...\n",
      "Processed 35840 texts...\n",
      "Processed 36160 texts...\n",
      "Processed 36480 texts...\n",
      "Processed 36800 texts...\n",
      "Processed 37120 texts...\n",
      "Processed 37440 texts...\n",
      "Processed 37760 texts...\n",
      "Processed 38080 texts...\n",
      "Processed 38400 texts...\n",
      "Processed 38720 texts...\n",
      "Processed 39040 texts...\n",
      "Processed 39360 texts...\n",
      "Processed 39680 texts...\n",
      "Processed 40000 texts...\n",
      "Processed 40320 texts...\n",
      "Processed 40640 texts...\n",
      "Processed 40960 texts...\n",
      "Processed 41280 texts...\n",
      "Processed 41600 texts...\n",
      "Processed 41920 texts...\n",
      "Processed 42240 texts...\n",
      "Processed 42560 texts...\n",
      "Processed 42880 texts...\n",
      "Processed 43200 texts...\n",
      "Processed 43520 texts...\n",
      "Processed 43840 texts...\n",
      "Processed 44160 texts...\n",
      "Processed 44480 texts...\n",
      "Processed 44800 texts...\n",
      "Processed 45120 texts...\n",
      "Processed 45440 texts...\n",
      "Processed 45760 texts...\n",
      "Processed 46080 texts...\n",
      "Processed 46400 texts...\n",
      "Processed 46720 texts...\n",
      "Processed 47040 texts...\n",
      "Processed 47360 texts...\n",
      "Processed 47680 texts...\n",
      "Processed 48000 texts...\n",
      "Processed 48320 texts...\n",
      "Processed 48640 texts...\n",
      "Processed 48960 texts...\n",
      "Processed 49280 texts...\n",
      "Processed 49600 texts...\n",
      "Processed 49920 texts...\n",
      "Completed processing 50000 texts\n"
     ]
    }
   ],
   "source": [
    "embeddings = preprocess_text_bert(sampled_df['cleaned_text'].tolist(), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:43.071491Z",
     "iopub.status.busy": "2024-11-21T08:05:43.071219Z",
     "iopub.status.idle": "2024-11-21T08:05:43.085022Z",
     "shell.execute_reply": "2024-11-21T08:05:43.084167Z",
     "shell.execute_reply.started": "2024-11-21T08:05:43.071466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "majority_label\n",
       "0    38936\n",
       "1     4750\n",
       "5     2746\n",
       "2     1812\n",
       "3     1645\n",
       "4      111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the group sizes\n",
    "sampled_df['majority_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:43.086222Z",
     "iopub.status.busy": "2024-11-21T08:05:43.086001Z",
     "iopub.status.idle": "2024-11-21T08:05:43.092274Z",
     "shell.execute_reply": "2024-11-21T08:05:43.091516Z",
     "shell.execute_reply.started": "2024-11-21T08:05:43.0862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampled_df = sampled_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, temp_data = train_test_split(sampled_df, test_size=0.4, random_state=42)\n",
    "\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:44.723521Z",
     "iopub.status.busy": "2024-11-21T08:05:44.723171Z",
     "iopub.status.idle": "2024-11-21T08:05:44.728355Z",
     "shell.execute_reply": "2024-11-21T08:05:44.727502Z",
     "shell.execute_reply.started": "2024-11-21T08:05:44.723489Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (30000, 9)\n",
      "Validation data size: (10000, 9)\n",
      "Testing data size: (10000, 9)\n"
     ]
    }
   ],
   "source": [
    "# Print the sizes of train and test sets\n",
    "print(\"Training data size:\", train_data.shape)\n",
    "print(\"Validation data size:\", val_data.shape)\n",
    "print(\"Testing data size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices for each split\n",
    "train_indices = train_data.index\n",
    "val_indices = val_data.index\n",
    "test_indices = test_data.index\n",
    "\n",
    "# Use these indices to get the corresponding embeddings\n",
    "X_train_text = embeddings[train_indices]\n",
    "X_val_text = embeddings[val_indices]\n",
    "X_test_text = embeddings[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess images for each split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:47.65783Z",
     "iopub.status.busy": "2024-11-21T08:05:47.656931Z",
     "iopub.status.idle": "2024-11-21T08:05:47.662629Z",
     "shell.execute_reply": "2024-11-21T08:05:47.661757Z",
     "shell.execute_reply.started": "2024-11-21T08:05:47.657779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        if not os.path.exists(img_path):\n",
    "            return np.zeros((target_size[0], target_size[1], 3))\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img = img_to_array(img) / 255.0\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        return np.zeros((target_size[0], target_size[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:05:49.025965Z",
     "iopub.status.busy": "2024-11-21T08:05:49.025195Z",
     "iopub.status.idle": "2024-11-21T08:07:03.227875Z",
     "shell.execute_reply": "2024-11-21T08:07:03.227124Z",
     "shell.execute_reply.started": "2024-11-21T08:05:49.025934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_image = np.array([load_and_preprocess_image(path) for path in train_data['image_path']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_image = np.array([load_and_preprocess_image(path) for path in val_data['image_path']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image = np.array([load_and_preprocess_image(path) for path in test_data['image_path']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get labels for each split\n",
    "y_train = np.array(train_data['majority_label'])\n",
    "y_val = np.array(val_data['majority_label'])\n",
    "y_test = np.array(test_data['majority_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:07:03.229567Z",
     "iopub.status.busy": "2024-11-21T08:07:03.229321Z",
     "iopub.status.idle": "2024-11-21T08:07:03.235252Z",
     "shell.execute_reply": "2024-11-21T08:07:03.234399Z",
     "shell.execute_reply.started": "2024-11-21T08:07:03.229544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 224, 224, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:07:03.23668Z",
     "iopub.status.busy": "2024-11-21T08:07:03.236327Z",
     "iopub.status.idle": "2024-11-21T08:07:03.24757Z",
     "shell.execute_reply": "2024-11-21T08:07:03.246868Z",
     "shell.execute_reply.started": "2024-11-21T08:07:03.236642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building: Multimodal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:07:03.249548Z",
     "iopub.status.busy": "2024-11-21T08:07:03.249286Z",
     "iopub.status.idle": "2024-11-21T08:07:05.721737Z",
     "shell.execute_reply": "2024-11-21T08:07:05.720804Z",
     "shell.execute_reply.started": "2024-11-21T08:07:03.249524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define image model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "x_image = base_model(image_input, training=False)\n",
    "x_image = GlobalAveragePooling2D()(x_image)\n",
    "x_image = Dense(256, activation='relu')(x_image)\n",
    "x_image = Dropout(0.5)(x_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:07:05.723394Z",
     "iopub.status.busy": "2024-11-21T08:07:05.72302Z",
     "iopub.status.idle": "2024-11-21T08:07:06.220376Z",
     "shell.execute_reply": "2024-11-21T08:07:06.219647Z",
     "shell.execute_reply.started": "2024-11-21T08:07:05.723332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define text model\n",
    "text_input = Input(shape=(768,))  # BERT base output dimension\n",
    "x_text = Dense(256, activation='relu')(text_input)\n",
    "x_text = Dropout(0.5)(x_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Multimodal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:07:06.221577Z",
     "iopub.status.busy": "2024-11-21T08:07:06.221314Z",
     "iopub.status.idle": "2024-11-21T08:07:06.244588Z",
     "shell.execute_reply": "2024-11-21T08:07:06.243666Z",
     "shell.execute_reply.started": "2024-11-21T08:07:06.221551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Combine image and text features\n",
    "combined = Concatenate()([x_image, x_text])\n",
    "x_combined = Dense(128, activation='relu')(combined)\n",
    "x_combined = Dropout(0.5)(x_combined)\n",
    "output = Dense(len(label_mapping), activation='softmax')(x_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:07:06.246144Z",
     "iopub.status.busy": "2024-11-21T08:07:06.24576Z",
     "iopub.status.idle": "2024-11-21T08:07:06.26394Z",
     "shell.execute_reply": "2024-11-21T08:07:06.263048Z",
     "shell.execute_reply.started": "2024-11-21T08:07:06.246102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "multimodal_model = Model(inputs=[image_input, text_input], outputs=output)\n",
    "multimodal_model.compile(optimizer=Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:07:06.265284Z",
     "iopub.status.busy": "2024-11-21T08:07:06.265017Z",
     "iopub.status.idle": "2024-11-21T08:07:06.298882Z",
     "shell.execute_reply": "2024-11-21T08:07:06.298014Z",
     "shell.execute_reply.started": "2024-11-21T08:07:06.265259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ resnet50            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ resnet50            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │ \u001b[38;5;34m23,587,712\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m524,544\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m196,864\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m65,664\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │        \u001b[38;5;34m774\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,375,558</span> (92.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,375,558\u001b[0m (92.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">787,846</span> (3.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m787,846\u001b[0m (3.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print Model Summary\n",
    "multimodal_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:07:06.300642Z",
     "iopub.status.busy": "2024-11-21T08:07:06.300016Z",
     "iopub.status.idle": "2024-11-21T08:13:56.054239Z",
     "shell.execute_reply": "2024-11-21T08:13:56.053287Z",
     "shell.execute_reply.started": "2024-11-21T08:07:06.300601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m 46/235\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:57\u001b[0m 3s/step - accuracy: 0.6823 - loss: 1.2185"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = multimodal_model.fit(\n",
    "    [X_train_image, X_train_text], y_train,\n",
    "    validation_data=([X_test_image, X_test_text], y_test),\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:22:43.894842Z",
     "iopub.status.busy": "2024-11-21T08:22:43.894118Z",
     "iopub.status.idle": "2024-11-21T08:22:44.384909Z",
     "shell.execute_reply": "2024-11-21T08:22:44.384121Z",
     "shell.execute_reply.started": "2024-11-21T08:22:43.894804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the entire binary model\n",
    "multimodal_model.save('multimodel_model_updated.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T08:23:23.588925Z",
     "iopub.status.busy": "2024-11-21T08:23:23.58821Z",
     "iopub.status.idle": "2024-11-21T08:23:29.816907Z",
     "shell.execute_reply": "2024-11-21T08:23:29.81612Z",
     "shell.execute_reply.started": "2024-11-21T08:23:23.588892Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = multimodal_model.evaluate([X_test_image, X_test_text], y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 966538,
     "sourceId": 1634802,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
